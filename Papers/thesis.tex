\title{High Performance Genetic Algorithms for Steganalysis}
\author{
Joseph Charles Bingham \\
Department of Mathematics\\
Iowa State University of Science and Technology\\
Ames, Iowa 50010, United States of America \\
jbingham@iastate.edu
}
\date{\today}

\documentclass[12pt]{article} 
\begin{document}
\maketitle
\textbf{array}
\begin{abstract}
\par This research will outline a novel implementation of a genetic algorithm that leverages high performance parallelizations to detect 
steganaraphically embedded images. The two main components that are new to this project are the application of parallelization for genetic algorithms and the application of genetic algorithm for steganalysis. Typical steganalytic methods which use machine learning techniques require an unreasonable amount of pre-classified data and copious amounts of time for training the engine. The data needed for such operation usually must be lab generated, which can lead to the biases when compared to real world, and often is constrained to specific parameters, such as they must remain within either the spacial domain or the JPEG domain, must be the same pixel width, etc., making these engines limited to what image space they detect over. The need for all data to be used in training the engine, as well as the linear nature of the engines used precludes them from being parallelized in any meaningful fashion. 
\par This new algorithm does not succumb to these shortfalls. By using solution sets of pixels as the data which the genetic engine trains over, and fixing the image(s) under suspicion, the engine can be parallelized, vastly increasing the efficiency. Since the algorithm searches for sets solutions and then uses a fitness function to determine whether the findings were statistically significant, it does not require training data at all, mean that there are no biases introduced by lab generated data. The algorithms flexibility does not limit it to just one format of images, meaning that the same program can be used without the need to generate a new set of data or train a new engine. 
\end{abstract}

\section{Background Information}
\paragraph{Steganography and Steganalysis}
\par Steganography is the practice of embedding information into photographs or audio media in such a way that it is not detectable to the average person. The form of steganography that the scope of this project will be most interested in is LSB (Least Significant Bit) embedding of images using random paths (1).
\par This, as the name suggests, is where the path of the embedding stream is random in nature. When a pixel from the image is selected to be altered, the least significant bit is overridden to be the same as the next bit in the embedding stream. Since it is just the least significant bit, very little visual alterations occur. This makes detection difficult, if not impossible without the aid of software. 
\par Steganalysis is the discovery of the existence of hidden information; therefore, like cryptography and cryptanalysis, the goal of steganalysis is to discover hidden information and to break the security of its carriers (2).
\paragraph{Genetic Algorithms}
\par Genetic Algorithms are algorithms that follow a specific machine learning paradigm (3). They are classified by their similarity to natural selection as found in evolution in the wild. They consist of three main parts: a cost function, a tester bot, and a builder bot.
\par The cost function determines the viability of each solution. Typically this function determines how well the solution completes the task that is trying to be accomplished, and is usually from ${\rm I\!R}^n \mapsto [0, 1]$. 
\par The tester bot tests each solution based on the cost function. Its job is to determine what the value of the test function and to rank each solution.
\par The builder bot takes each the best solutions, as ranked by the tester bot, generates more solutions based on their attributes. It generates the new solutions by randomly modifying the best solutions in hopes of descending the gradient.

\section{Implementation :: Theory}
\paragraph{Genetic Algorithm for Steganalysis}
\par One of the novel components to this research is the use of genetic algorithm for steganalysis. The thought behind this is to generate a classifier for steganographically embedded images versus normal cover images.
\par This will be done by creating a evolutionary solution for a path finding algorithm. The path finding algorithm will optimize the possible paths of embedding to determine the probability of payload being embedded. If the genetic algorithm's internal weight function is triggered, then the probability along the path found was deemed high enough to consider the image having a payload embedded.
\par The weight function is the $\chi ^ 2$-attack from steganalysis (4). The basis of this attack is that grey scale values that differ by only the last bit (the bit that is overwritten) will show up equally in the embedding path. This is because an LSB within the embedding path has an equal likelihood of being 0 or 1.
For example: \\
An image, I, whose pixels are represented by the matrix \\
$ \left[ \begin{array}{cccc}
 101 & 011 & 111 & 100\\
  001 & 001 & 100 & 001\\
 101 & 110 & 010 & 101 \\
 101 & 110 & 010 & 101 \\  \end{array} \right] $ 
 \\ with a lexicographical embedding of the message stream 
 \\ $ \left[ \begin{array}{c} 1,  0 , 1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0 \end{array} \right] $
\\ will become I'
 \\ $ \left[ \begin{array}{cccc}
 101 & 010 & 111 & 100\\
  001 & 000 & 101 & 000\\
 101 & 110 & 011 & 100 \\
 101 & 110 & 011 & 100 \\  \end{array} \right] $ 
 
\paragraph{Parallel Implementation of Genetic Algorithms}
\par The other novel component is the parallelization of genetic
algorithms to speed up the training time of the evolutionary model. The reason this project will require the will require a parallel training model, as opposed to a serial implementation, because the quantity of data that needs to be ingested by the engine is immense.
\par The parallelization will be achieved by using a "island" inspired model. This is where each node of the cluster getting its own evolutionary model, but with the same cost function. Then after some number of iterations, the nodes give each other their top solutions to reproduce with the other solutions. This will hopefully speed up, and aid with, the convex optimization.


\section{Implementation :: Code}

\section{Results}


\section{Conclusions}

\section{Bibliography}
(1) https://link.springer.com/article/10.1155/2010/876946 \\
(2) https://www.sans.org/reading-room/whitepapers/stenganography/steganalysis-detecting-hidden-information-computer-forensic-analysis-1014 \\
(3) https://link.springer.com/article/10.1007/BF00175354 \\
(4) https://orion.math.iastate.edu/dept/thesisarchive/MSCC/CStanleyMSSS05.pdf
\end{document}

